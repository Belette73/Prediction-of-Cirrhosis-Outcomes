{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db09b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385bed26-73b7-4038-8fb1-f0d9cafefde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour récupérer le chemin absolu d'un fichier placé au même endroit que le notebook en cours\n",
    "def get_output_path_file(output_filename):\n",
    "    notebook_filename = os.path.abspath(\"__file__\")\n",
    "    notebook_directory = os.path.dirname(notebook_filename)\n",
    "    return os.path.join(notebook_directory, output_filename)\n",
    "\n",
    "# fonction pour récupérer le chemin absolu d'un dossier placé au même endroit que le notebook en cours\n",
    "def get_output_path_folder(output_foldername):\n",
    "    notebook_filename = os.path.abspath(\"__file__\")\n",
    "    notebook_directory = os.path.dirname(notebook_filename)\n",
    "    return os.path.join(notebook_directory, output_foldername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c32a1ce-751a-463d-b7e3-d4a4e432e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def test_randomized_model(joblib_path_suivi_metrique_1, joblib_path_suivi_metrique_2, param_grid, model, randomized_search_CV):\n",
    "\n",
    "    param_grid_df =[]\n",
    "    for keys in param_grid:\n",
    "        param_grid_df.append(keys)\n",
    "     \n",
    "    if os.path.exists(joblib_path_suivi_metrique_1) and os.path.exists(joblib_path_suivi_metrique_2):\n",
    "        df_import_1 = load(joblib_path_suivi_metrique_1)\n",
    "        df_import_2 = load(joblib_path_suivi_metrique_2)\n",
    "        print(\"Récupération des DataFrames existants\")\n",
    "    else:\n",
    "        # Mettre à jour avec les paramètres pertinents pour XGBoost\n",
    "        df_import_1 = pd.DataFrame(columns=param_grid_df + ['LogLoss_mean', 'LogLoss_std'])\n",
    "        df_import_2 = pd.DataFrame(columns=[\"Best_param\", \"LogLoss\", \"Accuracy\", \"F1_weighted\", \"F1_macro\", \"Duree en sec randomized\"])\n",
    "        print(\"Création de nouveaux DataFrames\")\n",
    "        \n",
    "    \n",
    "\n",
    "    print(\"Début du randomized:\", randomized_search_CV)\n",
    "    debut = time.time()\n",
    "    randomized_search_CV.fit(X_train, y_train)\n",
    "    print(\"Fin du randomized:\", randomized_search_CV)\n",
    "    fin = time.time()\n",
    "    duree = fin - debut\n",
    "    results = randomized_search_CV.cv_results_\n",
    "\n",
    "    dico_param_grid = {param_grid_df[i]:results.get(\"param_\"+param_grid_df[i]) for i in range(len(param_grid_df))}\n",
    "    dico_metric = {'LogLoss_mean': results.get('mean_test_score'),\n",
    "                   'LogLoss_std': results.get('std_test_score')}\n",
    "    \n",
    "    combined_dict = {**dico_param_grid, **dico_metric}\n",
    "\n",
    "    df_score_random = pd.DataFrame(combined_dict)\n",
    "    \n",
    "    print(\"Début meilleur param:\", randomized_search_CV.best_params_)\n",
    "    best_params = randomized_search_CV.best_params_\n",
    "    best_model = XGBClassifier(**randomized_search_CV.best_params_)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    probs = best_model.predict_proba(X_test)\n",
    "    print(\"Fin meilleur param\")\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    logloss = log_loss(y_test, probs)\n",
    "\n",
    "    df_score_best_test = pd.DataFrame({\n",
    "        \"Best_param\": [best_params],\n",
    "        \"LogLoss\": [logloss],\n",
    "        \"Accuracy\": [accuracy],\n",
    "        \"F1_weighted\": [f1_weighted],\n",
    "        \"F1_macro\": [f1_macro],\n",
    "        \"Duree en sec randomized\": [duree]\n",
    "    })\n",
    "\n",
    "    df_score_random = pd.concat([df_import_1, df_score_random], ignore_index=True)\n",
    "    df_score_best_test = pd.concat([df_import_2, df_score_best_test], ignore_index=True)\n",
    "\n",
    "    return df_score_random, df_score_best_test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
