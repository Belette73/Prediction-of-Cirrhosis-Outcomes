{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f64aa3b-eb4e-4353-bc7d-650bdc74f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 0.0_Dependance.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade30732-f6e1-46c7-a6ae-e568651b2678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1797d83f-f16f-4e85-91c8-6e9d6906487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\",index_col=0)\n",
    "df[\"N_Week\"]=np.round((df['N_Days']/7),1)\n",
    "df[\"N_Year\"]=np.round((df['N_Days']/365),2)\n",
    "df.Age = np.round((df.Age)/365,1)\n",
    "\n",
    "#label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "colonne_a_encoder = [\"Sex\",\"Ascites\",\"Hepatomegaly\",\"Spiders\",\"Edema\",\"Drug\",\"Status\"]\t\n",
    "for i in colonne_a_encoder:\n",
    "    df[i] = le.fit_transform(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda9f6c1-4a30-464d-859c-71f9f37685f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    # Nombre d'arbres dans le boosting\n",
    "    'n_estimators': [50, 100, 250, 500, 1000],\n",
    "    \n",
    "    # Profondeur de chaque arbre\n",
    "    'max_depth': [3, 6, 9, 12],\n",
    "    \n",
    "    # Taux d'apprentissage (eta)\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    \n",
    "    # Minimum de perte de réduction nécessaire pour faire une partition supplémentaire sur un noeud de l'arbre\n",
    "    'gamma': [0, 0.1, 0.5, 1],\n",
    "    \n",
    "    # Fraction des observations à être randomisées pour chaque arbre\n",
    "    'subsample': [0.5, 0.75, 1],\n",
    "    \n",
    "    # Fraction de colonnes à être randomisées pour chaque arbre\n",
    "    'colsample_bytree': [0.5, 0.75, 1],\n",
    "    \n",
    "    # Le minimum de poids nécessaire pour une enfant\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    \n",
    "    # Regularisation L1 sur les poids\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    \n",
    "    # Regularisation L2 sur les poids\n",
    "    'reg_lambda': [0, 1, 10],\n",
    "    \n",
    "    # Choix de la fonction objectif, logloss pour la classification\n",
    "    'objective': ['multi:softprob'],\n",
    "    \n",
    "    # Choix de la stratégie d'évaluation pour le boosting\n",
    "    'eval_metric': ['mlogloss'],\n",
    "    \n",
    "    # Choix du booster\n",
    "    'booster': ['gbtree'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6dbbdf0-bd57-4dce-9ef1-8de64d6e45d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération des DataFrames existants\n",
      "Début du randomized: RandomizedSearchCV(cv=5,\n",
      "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
      "                                           callbacks=None,\n",
      "                                           colsample_bylevel=None,\n",
      "                                           colsample_bynode=None,\n",
      "                                           colsample_bytree=None, device=None,\n",
      "                                           early_stopping_rounds=None,\n",
      "                                           enable_categorical=False,\n",
      "                                           eval_metric=None, feature_types=None,\n",
      "                                           gamma=None, grow_policy=None,\n",
      "                                           importance_type=None,\n",
      "                                           interaction_constraints=None,\n",
      "                                           learning_rate...\n",
      "                   param_distributions={'booster': ['gbtree'],\n",
      "                                        'colsample_bytree': [0.5, 0.75, 1],\n",
      "                                        'eval_metric': ['mlogloss'],\n",
      "                                        'gamma': [0, 0.1, 0.5, 1],\n",
      "                                        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
      "                                        'max_depth': [3, 6, 9, 12],\n",
      "                                        'min_child_weight': [1, 5, 10],\n",
      "                                        'n_estimators': [50, 100, 250, 500,\n",
      "                                                         1000],\n",
      "                                        'objective': ['multi:softprob'],\n",
      "                                        'reg_alpha': [0, 0.1, 1],\n",
      "                                        'reg_lambda': [0, 1, 10],\n",
      "                                        'subsample': [0.5, 0.75, 1]},\n",
      "                   scoring='neg_log_loss')\n",
      "Fin du randomized: RandomizedSearchCV(cv=5,\n",
      "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
      "                                           callbacks=None,\n",
      "                                           colsample_bylevel=None,\n",
      "                                           colsample_bynode=None,\n",
      "                                           colsample_bytree=None, device=None,\n",
      "                                           early_stopping_rounds=None,\n",
      "                                           enable_categorical=False,\n",
      "                                           eval_metric=None, feature_types=None,\n",
      "                                           gamma=None, grow_policy=None,\n",
      "                                           importance_type=None,\n",
      "                                           interaction_constraints=None,\n",
      "                                           learning_rate...\n",
      "                   param_distributions={'booster': ['gbtree'],\n",
      "                                        'colsample_bytree': [0.5, 0.75, 1],\n",
      "                                        'eval_metric': ['mlogloss'],\n",
      "                                        'gamma': [0, 0.1, 0.5, 1],\n",
      "                                        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
      "                                        'max_depth': [3, 6, 9, 12],\n",
      "                                        'min_child_weight': [1, 5, 10],\n",
      "                                        'n_estimators': [50, 100, 250, 500,\n",
      "                                                         1000],\n",
      "                                        'objective': ['multi:softprob'],\n",
      "                                        'reg_alpha': [0, 0.1, 1],\n",
      "                                        'reg_lambda': [0, 1, 10],\n",
      "                                        'subsample': [0.5, 0.75, 1]},\n",
      "                   scoring='neg_log_loss')\n",
      "Début meilleur param: {'subsample': 0.75, 'reg_lambda': 0, 'reg_alpha': 0.1, 'objective': 'multi:softprob', 'n_estimators': 1000, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.01, 'gamma': 1, 'eval_metric': 'mlogloss', 'colsample_bytree': 0.5, 'booster': 'gbtree'}\n",
      "Fin meilleur param\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "joblib_path_suivi_metrique_1 = get_output_path_file(\"df_score_random.joblib\")\n",
    "joblib_path_suivi_metrique_2 = get_output_path_file(\"df_score_best_test.joblib\")\n",
    "\n",
    "target = df.Status\n",
    "data = df.drop(columns=[\"Status\",\"N_Days\",\"N_Week\"])\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data,target,test_size=0.2, random_state=123)\n",
    "#Standardisation\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Modèle instancié\n",
    "model = XGBClassifier(n_estimators=1000, max_depth=2, learning_rate=0.1, objective=\"multi:softprob\")\n",
    "\n",
    "randomized_search_CV = RandomizedSearchCV(model, param_distributions=param_grid,n_iter=2000, cv=5, scoring='neg_log_loss',n_jobs=-1)\n",
    "df_score_random,df_score_best_test = test_randomized_model(joblib_path_suivi_metrique_1, joblib_path_suivi_metrique_2, param_grid, model, randomized_search_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ac352b5-c9c1-4454-b01e-cf8fc574f4a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>objective</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>booster</th>\n",
       "      <th>LogLoss_mean</th>\n",
       "      <th>LogLoss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.495877</td>\n",
       "      <td>0.007797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.448388</td>\n",
       "      <td>0.014140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.440227</td>\n",
       "      <td>0.015089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.619045</td>\n",
       "      <td>0.030493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.466344</td>\n",
       "      <td>0.015956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.489187</td>\n",
       "      <td>0.019223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.449772</td>\n",
       "      <td>0.016963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.462370</td>\n",
       "      <td>0.021475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.453041</td>\n",
       "      <td>0.013892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>1000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.448730</td>\n",
       "      <td>0.015844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_estimators max_depth learning_rate gamma subsample colsample_bytree  \\\n",
       "0             250         9          0.01   0.1      0.75                1   \n",
       "1             100         3           0.2   0.5         1                1   \n",
       "2            1000         9          0.05     1       0.5              0.5   \n",
       "3             500        12           0.2     0      0.75             0.75   \n",
       "4             500         9           0.2     1       0.5                1   \n",
       "...           ...       ...           ...   ...       ...              ...   \n",
       "3995          500         3           0.2   0.1      0.75             0.75   \n",
       "3996          100        12           0.1   0.5       0.5                1   \n",
       "3997          250         9           0.2   0.5      0.75                1   \n",
       "3998          100         9           0.1     1         1                1   \n",
       "3999         1000        12          0.01     0      0.75                1   \n",
       "\n",
       "     min_child_weight reg_alpha reg_lambda       objective eval_metric  \\\n",
       "0                  10         1          1  multi:softprob    mlogloss   \n",
       "1                   1       0.1         10  multi:softprob    mlogloss   \n",
       "2                  10         1         10  multi:softprob    mlogloss   \n",
       "3                   5         0          0  multi:softprob    mlogloss   \n",
       "4                   5         0         10  multi:softprob    mlogloss   \n",
       "...               ...       ...        ...             ...         ...   \n",
       "3995                1         0          1  multi:softprob    mlogloss   \n",
       "3996                1         1          1  multi:softprob    mlogloss   \n",
       "3997                5         1          0  multi:softprob    mlogloss   \n",
       "3998               10         0          1  multi:softprob    mlogloss   \n",
       "3999               10         0          1  multi:softprob    mlogloss   \n",
       "\n",
       "     booster  LogLoss_mean  LogLoss_std  \n",
       "0     gbtree     -0.495877     0.007797  \n",
       "1     gbtree     -0.448388     0.014140  \n",
       "2     gbtree     -0.440227     0.015089  \n",
       "3     gbtree     -0.619045     0.030493  \n",
       "4     gbtree     -0.466344     0.015956  \n",
       "...      ...           ...          ...  \n",
       "3995  gbtree     -0.489187     0.019223  \n",
       "3996  gbtree     -0.449772     0.016963  \n",
       "3997  gbtree     -0.462370     0.021475  \n",
       "3998  gbtree     -0.453041     0.013892  \n",
       "3999  gbtree     -0.448730     0.015844  \n",
       "\n",
       "[4000 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0667e0aa-46e2-4775-8884-ce28bb9af9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best_param</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec randomized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha...</td>\n",
       "      <td>0.448550</td>\n",
       "      <td>0.826692</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.610022</td>\n",
       "      <td>3441.852242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'subsample': 0.75, 'reg_lambda': 0, 'reg_alph...</td>\n",
       "      <td>0.453031</td>\n",
       "      <td>0.822264</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.606093</td>\n",
       "      <td>3966.272579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Best_param   LogLoss  Accuracy  \\\n",
       "0  {'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha...  0.448550  0.826692   \n",
       "1  {'subsample': 0.75, 'reg_lambda': 0, 'reg_alph...  0.453031  0.822264   \n",
       "\n",
       "   F1_weighted  F1_macro  Duree en sec randomized  \n",
       "0     0.815207  0.610022              3441.852242  \n",
       "1     0.810324  0.606093              3966.272579  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_best_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1f28aa8-f0d9-4378-a3a8-eb42153333c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_score_best_test.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import load,dump\n",
    "dump(df_score_best_test,\"df_score_best_test.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef47b93-1749-4f16-89da-6bb8d91057c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_score_random.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(df_score_random,\"df_score_random.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70f2f96f-35db-4cad-bb7d-678bc724a9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>objective</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>booster</th>\n",
       "      <th>LogLoss_mean</th>\n",
       "      <th>LogLoss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.495877</td>\n",
       "      <td>0.007797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.448388</td>\n",
       "      <td>0.014140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.440227</td>\n",
       "      <td>0.015089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.619045</td>\n",
       "      <td>0.030493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.466344</td>\n",
       "      <td>0.015956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.489187</td>\n",
       "      <td>0.019223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.449772</td>\n",
       "      <td>0.016963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.462370</td>\n",
       "      <td>0.021475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.453041</td>\n",
       "      <td>0.013892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>1000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.448730</td>\n",
       "      <td>0.015844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_estimators max_depth learning_rate gamma subsample colsample_bytree  \\\n",
       "0             250         9          0.01   0.1      0.75                1   \n",
       "1             100         3           0.2   0.5         1                1   \n",
       "2            1000         9          0.05     1       0.5              0.5   \n",
       "3             500        12           0.2     0      0.75             0.75   \n",
       "4             500         9           0.2     1       0.5                1   \n",
       "...           ...       ...           ...   ...       ...              ...   \n",
       "3995          500         3           0.2   0.1      0.75             0.75   \n",
       "3996          100        12           0.1   0.5       0.5                1   \n",
       "3997          250         9           0.2   0.5      0.75                1   \n",
       "3998          100         9           0.1     1         1                1   \n",
       "3999         1000        12          0.01     0      0.75                1   \n",
       "\n",
       "     min_child_weight reg_alpha reg_lambda       objective eval_metric  \\\n",
       "0                  10         1          1  multi:softprob    mlogloss   \n",
       "1                   1       0.1         10  multi:softprob    mlogloss   \n",
       "2                  10         1         10  multi:softprob    mlogloss   \n",
       "3                   5         0          0  multi:softprob    mlogloss   \n",
       "4                   5         0         10  multi:softprob    mlogloss   \n",
       "...               ...       ...        ...             ...         ...   \n",
       "3995                1         0          1  multi:softprob    mlogloss   \n",
       "3996                1         1          1  multi:softprob    mlogloss   \n",
       "3997                5         1          0  multi:softprob    mlogloss   \n",
       "3998               10         0          1  multi:softprob    mlogloss   \n",
       "3999               10         0          1  multi:softprob    mlogloss   \n",
       "\n",
       "     booster  LogLoss_mean  LogLoss_std  \n",
       "0     gbtree     -0.495877     0.007797  \n",
       "1     gbtree     -0.448388     0.014140  \n",
       "2     gbtree     -0.440227     0.015089  \n",
       "3     gbtree     -0.619045     0.030493  \n",
       "4     gbtree     -0.466344     0.015956  \n",
       "...      ...           ...          ...  \n",
       "3995  gbtree     -0.489187     0.019223  \n",
       "3996  gbtree     -0.449772     0.016963  \n",
       "3997  gbtree     -0.462370     0.021475  \n",
       "3998  gbtree     -0.453041     0.013892  \n",
       "3999  gbtree     -0.448730     0.015844  \n",
       "\n",
       "[4000 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_random = load(\"df_score_random.joblib\")\n",
    "df_score_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce3a4d1a-ab70-4e68-94cd-92aa0f2a5cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best_param</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec randomized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha...</td>\n",
       "      <td>0.448550</td>\n",
       "      <td>0.826692</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.610022</td>\n",
       "      <td>3441.852242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'subsample': 0.75, 'reg_lambda': 0, 'reg_alph...</td>\n",
       "      <td>0.453031</td>\n",
       "      <td>0.822264</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.606093</td>\n",
       "      <td>3966.272579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Best_param   LogLoss  Accuracy  \\\n",
       "0  {'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha...  0.448550  0.826692   \n",
       "1  {'subsample': 0.75, 'reg_lambda': 0, 'reg_alph...  0.453031  0.822264   \n",
       "\n",
       "   F1_weighted  F1_macro  Duree en sec randomized  \n",
       "0     0.815207  0.610022              3441.852242  \n",
       "1     0.810324  0.606093              3966.272579  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_best_test=load(\"df_score_best_test.joblib\")\n",
    "df_score_best_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
