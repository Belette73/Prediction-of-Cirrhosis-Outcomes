{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f64aa3b-eb4e-4353-bc7d-650bdc74f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 0.0_Dependance.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1797d83f-f16f-4e85-91c8-6e9d6906487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\",index_col=0)\n",
    "df[\"N_Year\"]=np.round((df['N_Days']/365),2)\n",
    "df.Age = np.round((df.Age)/365,1)\n",
    "\n",
    "#label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "colonne_a_encoder = [\"Sex\",\"Ascites\",\"Hepatomegaly\",\"Spiders\",\"Edema\",\"Drug\",\"Status\"]\t\n",
    "for i in colonne_a_encoder:\n",
    "    df[i] = le.fit_transform(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28629e0d-afd9-49d1-91b1-56253a8d1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_initial = {\n",
    "    # Nombre d'arbres dans le boosting\n",
    "    'n_estimators': [50, 100, 250, 500, 1000],\n",
    "    \n",
    "    # Profondeur de chaque arbre\n",
    "    'max_depth': [3, 6, 9, 12],\n",
    "    \n",
    "    # Taux d'apprentissage (eta)\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    \n",
    "    # Minimum de perte de réduction nécessaire pour faire une partition supplémentaire sur un noeud de l'arbre\n",
    "    'gamma': [0, 0.1, 0.5, 1],\n",
    "    \n",
    "    # Fraction des observations à être randomisées pour chaque arbre\n",
    "    'subsample': [0.5, 0.75, 1],\n",
    "    \n",
    "    # Fraction de colonnes à être randomisées pour chaque arbre\n",
    "    'colsample_bytree': [0.5, 0.75, 1],\n",
    "    \n",
    "    # Le minimum de poids nécessaire pour une enfant\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    \n",
    "    # Regularisation L1 sur les poids\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    \n",
    "    # Regularisation L2 sur les poids\n",
    "    'reg_lambda': [0, 1, 10],\n",
    "    \n",
    "    # Choix de la fonction objectif, logloss pour la classification\n",
    "    'objective': ['multi:softprob'],\n",
    "    \n",
    "    # Choix de la stratégie d'évaluation pour le boosting\n",
    "    'eval_metric': ['mlogloss'],\n",
    "    \n",
    "    # Choix du booster\n",
    "    'booster': ['gbtree'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dda9f6c1-4a30-464d-859c-71f9f37685f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_ameliore = {\n",
    "    # Nombre d'arbres dans le boosting\n",
    "    'n_estimators': [400,500,600,700,800,900],\n",
    "    \n",
    "    # Profondeur de chaque arbre\n",
    "    'max_depth': [4,5,6],\n",
    "    \n",
    "    # Taux d'apprentissage (eta)\n",
    "    'learning_rate': [0.05,0.06,0.07,0.08,0.09,0.1],\n",
    "    \n",
    "    # Minimum de perte de réduction nécessaire pour faire une partition supplémentaire sur un noeud de l'arbre\n",
    "    'gamma': [0.5,0.7, 1],\n",
    "    \n",
    "    # Fraction des observations à être randomisées pour chaque arbre\n",
    "    'subsample': [0.75, 1],\n",
    "    \n",
    "    # Fraction de colonnes à être randomisées pour chaque arbre\n",
    "    'colsample_bytree': [0.2,0.4,0.5,0.6],\n",
    "    \n",
    "    # Le minimum de poids nécessaire pour une enfant\n",
    "    'min_child_weight': [ 5,6,7,8,9,10],\n",
    "    \n",
    "    # Regularisation L1 sur les poids\n",
    "    'reg_alpha': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1],\n",
    "    \n",
    "    # Regularisation L2 sur les poids\n",
    "    'reg_lambda': [0, 1,2,3,4,5,6,7,8,9,10],\n",
    "    \n",
    "    # Choix de la fonction objectif, logloss pour la classification\n",
    "    'objective': ['multi:softprob'],\n",
    "    \n",
    "    # Choix de la stratégie d'évaluation pour le boosting\n",
    "    'eval_metric': ['mlogloss'],\n",
    "    \n",
    "    # Choix du booster\n",
    "    'booster': ['gbtree'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbbdf0-bd57-4dce-9ef1-8de64d6e45d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création de nouveaux DataFrames\n",
      "Début du randomized: RandomizedSearchCV(cv=5,\n",
      "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
      "                                           callbacks=None,\n",
      "                                           colsample_bylevel=None,\n",
      "                                           colsample_bynode=None,\n",
      "                                           colsample_bytree=None, device=None,\n",
      "                                           early_stopping_rounds=None,\n",
      "                                           enable_categorical=False,\n",
      "                                           eval_metric=None, feature_types=None,\n",
      "                                           gamma=None, grow_policy=None,\n",
      "                                           importance_type=None,\n",
      "                                           interaction_constraints=None,\n",
      "                                           learning_rate...\n",
      "                   param_distributions={'booster': ['gbtree'],\n",
      "                                        'colsample_bytree': [0.5, 0.75, 1],\n",
      "                                        'eval_metric': ['mlogloss'],\n",
      "                                        'gamma': [0, 0.1, 0.5, 1],\n",
      "                                        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
      "                                        'max_depth': [3, 6, 9, 12],\n",
      "                                        'min_child_weight': [1, 5, 10],\n",
      "                                        'n_estimators': [50, 100, 250, 500,\n",
      "                                                         1000],\n",
      "                                        'objective': ['multi:softprob'],\n",
      "                                        'reg_alpha': [0, 0.1, 1],\n",
      "                                        'reg_lambda': [0, 1, 10],\n",
      "                                        'subsample': [0.5, 0.75, 1]},\n",
      "                   scoring='neg_log_loss')\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "joblib_path_suivi_metrique_1 = get_output_path_file(\"df_score_random_v1.joblib\")\n",
    "joblib_path_suivi_metrique_2 = get_output_path_file(\"df_score_best_test_v1.joblib\")\n",
    "\n",
    "target = df.Status\n",
    "data = df.drop(columns=[\"Status\",\"N_Days\"])\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data,target,test_size=0.2, random_state=123)\n",
    "#Standardisation\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Modèle instancié\n",
    "model = XGBClassifier(n_estimators=1000, max_depth=2, learning_rate=0.1, objective=\"multi:softprob\")\n",
    "\n",
    "randomized_search_CV = RandomizedSearchCV(model, param_distributions=param_grid,n_iter=2000, cv=5, scoring='neg_log_loss',n_jobs=-1)\n",
    "df_score_random_v1,df_score_best_test_v1 = test_randomized_model(joblib_path_suivi_metrique_1, joblib_path_suivi_metrique_2, param_grid_ameliore, model, randomized_search_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ac352b5-c9c1-4454-b01e-cf8fc574f4a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>objective</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>booster</th>\n",
       "      <th>LogLoss_mean</th>\n",
       "      <th>LogLoss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.495877</td>\n",
       "      <td>0.007797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.448388</td>\n",
       "      <td>0.014140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.440227</td>\n",
       "      <td>0.015089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.619045</td>\n",
       "      <td>0.030493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.466344</td>\n",
       "      <td>0.015956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18495</th>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.457141</td>\n",
       "      <td>0.016801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18496</th>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.814215</td>\n",
       "      <td>0.002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18497</th>\n",
       "      <td>500</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.521037</td>\n",
       "      <td>0.020914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18498</th>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.644294</td>\n",
       "      <td>0.005311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18499</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.680357</td>\n",
       "      <td>0.002198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18500 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_estimators max_depth learning_rate gamma subsample colsample_bytree  \\\n",
       "0              250         9          0.01   0.1      0.75                1   \n",
       "1              100         3           0.2   0.5         1                1   \n",
       "2             1000         9          0.05     1       0.5              0.5   \n",
       "3              500        12           0.2     0      0.75             0.75   \n",
       "4              500         9           0.2     1       0.5                1   \n",
       "...            ...       ...           ...   ...       ...              ...   \n",
       "18495          250         3           0.2   0.5      0.75             0.75   \n",
       "18496           50         9          0.01     1      0.75              0.5   \n",
       "18497          500         9           0.2   0.1      0.75                1   \n",
       "18498          100         9          0.01     0         1             0.75   \n",
       "18499          100         3          0.01   0.5         1                1   \n",
       "\n",
       "      min_child_weight reg_alpha reg_lambda       objective eval_metric  \\\n",
       "0                   10         1          1  multi:softprob    mlogloss   \n",
       "1                    1       0.1         10  multi:softprob    mlogloss   \n",
       "2                   10         1         10  multi:softprob    mlogloss   \n",
       "3                    5         0          0  multi:softprob    mlogloss   \n",
       "4                    5         0         10  multi:softprob    mlogloss   \n",
       "...                ...       ...        ...             ...         ...   \n",
       "18495                5         0          0  multi:softprob    mlogloss   \n",
       "18496               10         1          0  multi:softprob    mlogloss   \n",
       "18497               10         1          0  multi:softprob    mlogloss   \n",
       "18498               10         0          0  multi:softprob    mlogloss   \n",
       "18499               10         1         10  multi:softprob    mlogloss   \n",
       "\n",
       "      booster  LogLoss_mean  LogLoss_std  \n",
       "0      gbtree     -0.495877     0.007797  \n",
       "1      gbtree     -0.448388     0.014140  \n",
       "2      gbtree     -0.440227     0.015089  \n",
       "3      gbtree     -0.619045     0.030493  \n",
       "4      gbtree     -0.466344     0.015956  \n",
       "...       ...           ...          ...  \n",
       "18495  gbtree     -0.457141     0.016801  \n",
       "18496  gbtree     -0.814215     0.002704  \n",
       "18497  gbtree     -0.521037     0.020914  \n",
       "18498  gbtree     -0.644294     0.005311  \n",
       "18499  gbtree     -0.680357     0.002198  \n",
       "\n",
       "[18500 rows x 14 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_random_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0667e0aa-46e2-4775-8884-ce28bb9af9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best_param</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec randomized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha...</td>\n",
       "      <td>0.448550</td>\n",
       "      <td>0.826692</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.610022</td>\n",
       "      <td>3441.852242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'subsample': 0.75, 'reg_lambda': 0, 'reg_alph...</td>\n",
       "      <td>0.453031</td>\n",
       "      <td>0.822264</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.606093</td>\n",
       "      <td>3966.272579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'subsample': 0.75, 'reg_lambda': 1, 'reg_alph...</td>\n",
       "      <td>0.450924</td>\n",
       "      <td>0.826692</td>\n",
       "      <td>0.816315</td>\n",
       "      <td>0.625979</td>\n",
       "      <td>966.120473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha...</td>\n",
       "      <td>0.447097</td>\n",
       "      <td>0.824162</td>\n",
       "      <td>0.812921</td>\n",
       "      <td>0.607456</td>\n",
       "      <td>3853.032981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'subsample': 0.5, 'reg_lambda': 1, 'reg_alpha...</td>\n",
       "      <td>0.448739</td>\n",
       "      <td>0.824794</td>\n",
       "      <td>0.812801</td>\n",
       "      <td>0.598961</td>\n",
       "      <td>3708.291542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'subsample': 0.5, 'reg_lambda': 1, 'reg_alpha...</td>\n",
       "      <td>0.447176</td>\n",
       "      <td>0.824794</td>\n",
       "      <td>0.813524</td>\n",
       "      <td>0.607785</td>\n",
       "      <td>18971.756044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Best_param   LogLoss  Accuracy  \\\n",
       "0  {'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha...  0.448550  0.826692   \n",
       "1  {'subsample': 0.75, 'reg_lambda': 0, 'reg_alph...  0.453031  0.822264   \n",
       "2  {'subsample': 0.75, 'reg_lambda': 1, 'reg_alph...  0.450924  0.826692   \n",
       "3  {'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha...  0.447097  0.824162   \n",
       "4  {'subsample': 0.5, 'reg_lambda': 1, 'reg_alpha...  0.448739  0.824794   \n",
       "5  {'subsample': 0.5, 'reg_lambda': 1, 'reg_alpha...  0.447176  0.824794   \n",
       "\n",
       "   F1_weighted  F1_macro  Duree en sec randomized  \n",
       "0     0.815207  0.610022              3441.852242  \n",
       "1     0.810324  0.606093              3966.272579  \n",
       "2     0.816315  0.625979               966.120473  \n",
       "3     0.812921  0.607456              3853.032981  \n",
       "4     0.812801  0.598961              3708.291542  \n",
       "5     0.813524  0.607785             18971.756044  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_best_test_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1f28aa8-f0d9-4378-a3a8-eb42153333c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_score_best_test.joblib']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import load,dump\n",
    "dump(df_score_best_test_v1,\"df_score_best_test_v1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bef47b93-1749-4f16-89da-6bb8d91057c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_score_random.joblib']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(df_score_random_v1,\"df_score_random_v1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70f2f96f-35db-4cad-bb7d-678bc724a9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>gamma</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>objective</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>booster</th>\n",
       "      <th>LogLoss_mean</th>\n",
       "      <th>LogLoss_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.495877</td>\n",
       "      <td>0.007797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.448388</td>\n",
       "      <td>0.014140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.440227</td>\n",
       "      <td>0.015089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.619045</td>\n",
       "      <td>0.030493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.466344</td>\n",
       "      <td>0.015956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>250</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.444509</td>\n",
       "      <td>0.014346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.477466</td>\n",
       "      <td>0.006022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.441659</td>\n",
       "      <td>0.014930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.565322</td>\n",
       "      <td>0.022599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>-0.468461</td>\n",
       "      <td>0.008556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_estimators max_depth learning_rate gamma subsample colsample_bytree  \\\n",
       "0             250         9          0.01   0.1      0.75                1   \n",
       "1             100         3           0.2   0.5         1                1   \n",
       "2            1000         9          0.05     1       0.5              0.5   \n",
       "3             500        12           0.2     0      0.75             0.75   \n",
       "4             500         9           0.2     1       0.5                1   \n",
       "...           ...       ...           ...   ...       ...              ...   \n",
       "4495          250         6          0.05     0      0.75                1   \n",
       "4496          100         3          0.05   0.5         1                1   \n",
       "4497          250         3           0.1     1      0.75                1   \n",
       "4498         1000         6           0.2   0.1      0.75              0.5   \n",
       "4499          100         3          0.05   0.5      0.75                1   \n",
       "\n",
       "     min_child_weight reg_alpha reg_lambda       objective eval_metric  \\\n",
       "0                  10         1          1  multi:softprob    mlogloss   \n",
       "1                   1       0.1         10  multi:softprob    mlogloss   \n",
       "2                  10         1         10  multi:softprob    mlogloss   \n",
       "3                   5         0          0  multi:softprob    mlogloss   \n",
       "4                   5         0         10  multi:softprob    mlogloss   \n",
       "...               ...       ...        ...             ...         ...   \n",
       "4495               10         0          0  multi:softprob    mlogloss   \n",
       "4496               10         0         10  multi:softprob    mlogloss   \n",
       "4497                5         1          1  multi:softprob    mlogloss   \n",
       "4498               10       0.1          0  multi:softprob    mlogloss   \n",
       "4499                1       0.1          0  multi:softprob    mlogloss   \n",
       "\n",
       "     booster  LogLoss_mean  LogLoss_std  \n",
       "0     gbtree     -0.495877     0.007797  \n",
       "1     gbtree     -0.448388     0.014140  \n",
       "2     gbtree     -0.440227     0.015089  \n",
       "3     gbtree     -0.619045     0.030493  \n",
       "4     gbtree     -0.466344     0.015956  \n",
       "...      ...           ...          ...  \n",
       "4495  gbtree     -0.444509     0.014346  \n",
       "4496  gbtree     -0.477466     0.006022  \n",
       "4497  gbtree     -0.441659     0.014930  \n",
       "4498  gbtree     -0.565322     0.022599  \n",
       "4499  gbtree     -0.468461     0.008556  \n",
       "\n",
       "[4500 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_random = load(\"df_score_random.joblib\")\n",
    "df_score_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce3a4d1a-ab70-4e68-94cd-92aa0f2a5cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best_param</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec randomized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha...</td>\n",
       "      <td>0.448550</td>\n",
       "      <td>0.826692</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.610022</td>\n",
       "      <td>3441.852242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'subsample': 0.75, 'reg_lambda': 0, 'reg_alph...</td>\n",
       "      <td>0.453031</td>\n",
       "      <td>0.822264</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>0.606093</td>\n",
       "      <td>3966.272579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'subsample': 0.75, 'reg_lambda': 1, 'reg_alph...</td>\n",
       "      <td>0.450924</td>\n",
       "      <td>0.826692</td>\n",
       "      <td>0.816315</td>\n",
       "      <td>0.625979</td>\n",
       "      <td>966.120473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Best_param   LogLoss  Accuracy  \\\n",
       "0  {'subsample': 0.5, 'reg_lambda': 0, 'reg_alpha...  0.448550  0.826692   \n",
       "1  {'subsample': 0.75, 'reg_lambda': 0, 'reg_alph...  0.453031  0.822264   \n",
       "2  {'subsample': 0.75, 'reg_lambda': 1, 'reg_alph...  0.450924  0.826692   \n",
       "\n",
       "   F1_weighted  F1_macro  Duree en sec randomized  \n",
       "0     0.815207  0.610022              3441.852242  \n",
       "1     0.810324  0.606093              3966.272579  \n",
       "2     0.816315  0.625979               966.120473  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_best_test=load(\"df_score_best_test.joblib\")\n",
    "df_score_best_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
