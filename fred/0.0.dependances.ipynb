{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a45b50c-1fdd-4a72-90a0-56d0cbb6e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Rectangle\n",
    "from prettytable import PrettyTable\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "\n",
    "from catboost import Pool\n",
    "from scipy.stats import uniform\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "137020d8-3d95-4628-a830-b9e8431d5510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_col_dtypes(df, target, limit = 3):\n",
    "    \"\"\"\n",
    "    Cette fonction va distinguer les variables numériques et catégorielles selon une limite de valeurs uniques\n",
    "    Elle affiche aussi le type des variables dans le df inital\n",
    "    \"\"\"\n",
    "    num_cols = df.select_dtypes(\"number\").columns.to_list()\n",
    "    cat_cols = df.select_dtypes(\"object\").columns.to_list()\n",
    "    cardinals = [col for col in cat_cols if df[col].nunique() == df.shape[0]]\n",
    "    cat_but_num = [col for col in cat_cols if (df[col].nunique() > limit) & (col not in cardinals)]\n",
    "    cat_cols = [col for col in df.columns if (df[col].nunique() < limit) & (col not in [target])]\n",
    "    num_cols = [col for col in num_cols if (col not in cat_cols) & (col not in [target])] + cat_but_num\n",
    "   \n",
    "    print(f\"Colonnes numériques : {num_cols}\", end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Voici le type des colonnes numériques : \", end=\"\\n\\n\")\n",
    "    df[num_cols].info()\n",
    "    \n",
    "    print(f\"Colonnes catégorielles : {cat_cols}\", end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Voici le type des colonnes catégorielles: \", end=\"\\n\\n\")\n",
    "    df[cat_cols].info()    \n",
    "  \n",
    "    return num_cols, cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3893a26-8b7c-43c4-a02d-6c5b5838ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploration(df):\n",
    "    #Nan et doublons\n",
    "    print(\"Ce dataframe comporte \",df.shape[0], \"lignes et \",df.shape[1], \"colonnes.\")\n",
    "    print(\"Il comporte \", df.isna().sum().sum(), \"lignes comportant des Nan et \", df.duplicated().sum().sum(),\"doublons.\")\n",
    "    \n",
    "    #DEscription features\n",
    "    print(\"Voici une description des features : \",end=\"\\n\\n\") \n",
    "    imageLue = Image.open(\"images\\Description_features_detail.png\")\n",
    "    fig = plt.figure(figsize=(14,16))\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Features\",\"Unique Values\"]\n",
    "    for i in list(df_train.columns) :\n",
    "        nunique =df_train[str(i)].nunique\n",
    "        table.add_row([i, f\"{nunique()}\"])\n",
    "    print('Unique values in categorical columns : \\n')\n",
    "    print(table)\n",
    "    plt.imshow(imageLue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "186750ec-e70b-4f0d-9683-898a077d8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    #chermin vers les données\n",
    "    path = r\"C:\\Users\\Frederic\\Documents\\GitHub\\Tennis_analysis\\Prediction-of-Cirrhosis-Outcomes\"\n",
    "    train_path = os.path.abspath(path) + \"/data\" +\"/train.csv\"\n",
    "    test_path = os.path.abspath(path) + \"/data\" +\"/test.csv\"\n",
    "    \n",
    "    print(\"creation de df_train\")\n",
    "    df_train = pd.read_csv(train_path,index_col='id')\n",
    "    #print(df_train.head())\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"identification des variables numériques et catégorielles \")\n",
    "    #identification colonnes numériques et catégorielles\n",
    "    num_cols, cat_cols = find_col_dtypes(df=df_train, target='Status', limit = 4)\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"la cible est la colonne :\", df_train.columns.get_loc('Status'))\n",
    "          \n",
    "    #LabelEncoder pour les variables catégorielles\n",
    "    print(\"Colonnes catégorielles : \",cat_cols,end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Encodage des variables catégorielles avec Labelencoder\")  \n",
    "    le = LabelEncoder()\n",
    "    for column in cat_cols:\n",
    "        df_train[column] = le.fit_transform(df_train[column])\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "\n",
    "    # Séparation des fonctionnalités et de la variable cible\n",
    "    y=df_train['Status']\n",
    "    #Utilisation de LabelBinarizer pour encoder la variable cible 'Status'\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    y_encoded = label_binarizer.fit_transform(y)\n",
    "    df_train['Status'] = y_encoded\n",
    "\n",
    "    print(\"préparation des données\")\n",
    "    #Préparation des données\n",
    "    target = df_train.Status\n",
    "    data = df_train.drop(columns=[\"Status\"])\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    cat_indicies = []\n",
    "    for column in cat_cols:\n",
    "        data[column] = data[column].astype('category')\n",
    "        cat_indicies.append(data.columns.get_loc(column)) # renvoie les indices de toutes les colonnes non numériques sous forme de liste.\n",
    "    print(\"--> les indices des colonnes catégorielles sont : \",cat_indicies)\n",
    "     \n",
    "    X_train,X_test,y_train,y_test = train_test_split(data,target,test_size=0.2, random_state=1)\n",
    "    \n",
    "    print(\"préparation des données avec Robustscaler\")\n",
    "    #Standardisation des variables\n",
    "    robustscaler = RobustScaler().fit(X_train)\n",
    "    X_train = robustscaler.transform(X_train)\n",
    "    X_test = robustscaler.transform(X_test)\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    data=np.concatenate([X_train,X_test],axis=0)\n",
    "   \n",
    "    #transformation en matrice\n",
    "    variables = [X_train, X_test, data, target, y_test, y_train]\n",
    "\n",
    "    for i in range(len(variables)):\n",
    "        objet = variables[i]\n",
    "        if isinstance(objet, np.ndarray):\n",
    "            pass  # No need to change, already a NumPy array\n",
    "        else:\n",
    "            variables[i] = objet.to_numpy()\n",
    "\n",
    "    # Now variables[0], variables[1], etc. hold the NumPy arrays\n",
    "    X_train, X_test, data, target, y_test, y_train = variables    \n",
    "  \n",
    "    return X_train,X_test,y_train,y_test,target,data,cat_indicies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e38f5b52-a4b9-4298-970b-c7c20e1bb52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data2():\n",
    "    #chermin vers les données\n",
    "    path = r\"C:\\Users\\Frederic\\Documents\\GitHub\\Tennis_analysis\\Prediction-of-Cirrhosis-Outcomes\"\n",
    "    train_path = os.path.abspath(path) + \"/data\" +\"/train.csv\"\n",
    "    test_path = os.path.abspath(path) + \"/data\" +\"/test.csv\"\n",
    "    \n",
    "    print(\"creation de df_train\")\n",
    "    df_train = pd.read_csv(train_path,index_col='id')\n",
    "    df_train  = df_train.drop(columns=[\"Drug\"])\n",
    "    \n",
    "    #print(df_train.head())\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"identification des variables numériques et catégorielles \")\n",
    "    #identification colonnes numériques et catégorielles\n",
    "    num_cols, cat_cols = find_col_dtypes(df=df_train, target='Status', limit = 4)\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"la cible est la colonne :\", df_train.columns.get_loc('Status'))\n",
    "          \n",
    "    #LabelEncoder pour les variables catégorielles\n",
    "    print(\"Colonnes catégorielles : \",cat_cols,end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Encodage des variables catégorielles avec Labelencoder\")  \n",
    "    le = LabelEncoder()\n",
    "    for column in cat_cols:\n",
    "        df_train[column] = le.fit_transform(df_train[column])\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "\n",
    "    # Séparation des fonctionnalités et de la variable cible\n",
    "    y=df_train['Status']\n",
    "    #Utilisation de LabelBinarizer pour encoder la variable cible 'Status'\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    y_encoded = label_binarizer.fit_transform(y)\n",
    "    df_train['Status'] = y_encoded\n",
    "\n",
    "    print(\"préparation des données\")\n",
    "    #Préparation des données\n",
    "    target = df_train.Status\n",
    "    data = df_train.drop(columns=[\"Status\"])\n",
    "    print(\"--> Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    cat_indicies = []\n",
    "    for column in cat_cols:\n",
    "        data[column] = data[column].astype('category')\n",
    "        cat_indicies.append(data.columns.get_loc(column)) # renvoie les indices de toutes les colonnes non numériques sous forme de liste.\n",
    "    print(\"--> les indices des colonnes catégorielles sont : \",cat_indicies)\n",
    "     \n",
    "    X_train,X_test,y_train,y_test = train_test_split(data,target,test_size=0.2, random_state=1)\n",
    "    \n",
    "    print(\"préparation des données avec Robustscaler\")\n",
    "    #Standardisation des variables\n",
    "    robustscaler = RobustScaler().fit(X_train)\n",
    "    X_train = robustscaler.transform(X_train)\n",
    "    X_test = robustscaler.transform(X_test)\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    data=np.concatenate([X_train,X_test],axis=0)\n",
    "   \n",
    "    #transformation en matrice\n",
    "    variables = [X_train, X_test, data, target, y_test, y_train]\n",
    "\n",
    "    for i in range(len(variables)):\n",
    "        objet = variables[i]\n",
    "        if isinstance(objet, np.ndarray):\n",
    "            pass  # No need to change, already a NumPy array\n",
    "        else:\n",
    "            variables[i] = objet.to_numpy()\n",
    "\n",
    "    # Now variables[0], variables[1], etc. hold the NumPy arrays\n",
    "    X_train, X_test, data, target, y_test, y_train = variables    \n",
    "  \n",
    "    return X_train,X_test,y_train,y_test,target,data,cat_indicies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfef08c-44cc-49f2-8631-a622860f5b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data3():\n",
    "    #chermin vers les données\n",
    "    path = r\"C:\\Users\\Frederic\\Documents\\GitHub\\Tennis_analysis\\Prediction-of-Cirrhosis-Outcomes\"\n",
    "    train_path = os.path.abspath(path) + \"/data\" +\"/train.csv\"\n",
    "    test_path = os.path.abspath(path) + \"/data\" +\"/test.csv\"\n",
    "    \n",
    "    print(\"creation de df_train\")\n",
    "    df_train = pd.read_csv(train_path,index_col='id')\n",
    "    df_train  = df_train.drop(columns=[\"Drug\"])\n",
    "    \n",
    "    #print(df_train.head())\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"identification des variables numériques et catégorielles \")\n",
    "    #identification colonnes numériques et catégorielles\n",
    "    num_cols, cat_cols = find_col_dtypes(df=df_train, target='Status', limit = 4)\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"la cible est la colonne :\", df_train.columns.get_loc('Status'))\n",
    "          \n",
    "    #LabelEncoder pour les variables catégorielles\n",
    "    print(\"Colonnes catégorielles : \",cat_cols,end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Encodage des variables catégorielles avec Labelencoder\")  \n",
    "    le = LabelEncoder()\n",
    "    for column in cat_cols:\n",
    "        df_train[column] = le.fit_transform(df_train[column])\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "\n",
    "    # Séparation des fonctionnalités et de la variable cible\n",
    "    y=df_train['Status']\n",
    "    #Utilisation de LabelBinarizer pour encoder la variable cible 'Status'\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    df_train['Status'] = y_encoded\n",
    "\n",
    "    print(\"préparation des données\")\n",
    "    #Préparation des données\n",
    "    target = df_train.Status\n",
    "    data = df_train.drop(columns=[\"Status\"])\n",
    "    print(\"--> Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    cat_indicies = []\n",
    "    for column in cat_cols:\n",
    "        data[column] = data[column].astype('category')\n",
    "        cat_indicies.append(data.columns.get_loc(column)) # renvoie les indices de toutes les colonnes non numériques sous forme de liste.\n",
    "    print(\"--> les indices des colonnes catégorielles sont : \",cat_indicies)\n",
    "     \n",
    "    X_train,X_test,y_train,y_test = train_test_split(data,target,test_size=0.2, random_state=1)\n",
    "    \n",
    "    print(\"préparation des données avec Robustscaler\")\n",
    "    #Standardisation des variables\n",
    "    robustscaler = RobustScaler().fit(X_train)\n",
    "    X_train = robustscaler.transform(X_train)\n",
    "    X_test = robustscaler.transform(X_test)\n",
    "    print(\"-->Done\",end=\"\\n\\n\")\n",
    "    \n",
    "    data=np.concatenate([X_train,X_test],axis=0)\n",
    "   \n",
    "    #transformation en matrice\n",
    "    variables = [X_train, X_test, data, target, y_test, y_train]\n",
    "\n",
    "    for i in range(len(variables)):\n",
    "        objet = variables[i]\n",
    "        if isinstance(objet, np.ndarray):\n",
    "            pass  # No need to change, already a NumPy array\n",
    "        else:\n",
    "            variables[i] = objet.to_numpy()\n",
    "\n",
    "    # Now variables[0], variables[1], etc. hold the NumPy arrays\n",
    "    X_train, X_test, data, target, y_test, y_train = variables    \n",
    "  \n",
    "    return X_train,X_test,y_train,y_test,target,data,cat_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2143ffd6-9517-4e2b-a725-9ad839379aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    data={'feature_names':feature_names,\n",
    "         'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    fi_df.sort_values(by=['feature_importance'],    \n",
    "                     ascending=False,inplace=True)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x=fi_df['feature_importance'], \n",
    "               y=fi_df['feature_names'])\n",
    "    plt.title(model_type + ' FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227f4a2-d8b5-4284-ad66-574fd0641037",
   "metadata": {},
   "source": [
    "## Explications Encodage des variables catégorielles\n",
    "\"\"\"\n",
    "Label encoding is a technique where categorical data is represented as numerical values.\n",
    "each unique category or label is assigned a unique integer value. Often used when working with algorithms\n",
    "that require numerical input, such as decision trees and support vector machines.\n",
    "                                                                    \n",
    "one-hot encoding : label encoding introduces ordinal relationships between the categories, which might not be appropriate for all types of\n",
    "categorical variables. For example, if you have nominal data (categories with no inherent order), using one-hot encoding might be more suitable.\n",
    "\n",
    "Binary encoding is another technique used in data preprocessing, especially with categorical data. It transforms categorical values into\n",
    "binary code, which is particularly useful when dealing with high-cardinality categorical features (features with a large number of\n",
    "unique categories). Binary encoding reduces the dimensionality of the data compared to one-hot encoding, making it more memory-efficient.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa66686-e9dd-409b-a2d6-35f256976322",
   "metadata": {},
   "source": [
    "<img src=\"Encodage_variables.png\" width=\"800\" height=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e62212-8021-4fa2-8b77-e1b5565e9e6a",
   "metadata": {},
   "source": [
    "[Lien vers un notebook Kaggle](https://www.kaggle.com/code/markuslill/s3e26-xgbclassifer?scriptVersionId=155239835&cellId=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c374b43-1acb-4c3c-bcaf-e80877b7e0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
